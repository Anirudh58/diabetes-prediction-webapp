{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "308f9dc0-6c5e-4c6c-bf35-8707912c8522",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30e063d-7454-460a-b236-3c17d5524ebe",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53788864-6bc3-447f-9c85-7fd5e1d09a90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "root_dir = \"./../\"\n",
    "data_path = os.path.join(root_dir, 'data')\n",
    "diabetes_dataset_path = os.path.join(data_path, 'diabetes.csv')\n",
    "models_path = os.path.join(root_dir, 'models')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df752006-812e-49f2-bbdf-4636b2ade449",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b389da7-00d6-4abc-abde-c30df7d9542e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age'] Predict: Outcome\n"
     ]
    }
   ],
   "source": [
    "df_diabetes = pd.read_csv(diabetes_dataset_path)\n",
    "print(f\"Features: {list(df_diabetes.columns[:-1])} Predict: {df_diabetes.columns[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35348f07-8e75-4251-a1e3-2fccf68c65e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive labels (Outcome=1): 268\n",
      "Negative labels (Outcome=0): 500\n"
     ]
    }
   ],
   "source": [
    "# count the number of positive and negative labels\n",
    "counts = df_diabetes[\"Outcome\"].value_counts()\n",
    "\n",
    "# print the counts\n",
    "print(\"Positive labels (Outcome=1):\", counts[1])\n",
    "print(\"Negative labels (Outcome=0):\", counts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4636676b-5bd1-45a7-93bf-abdf6493af37",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abaf94f4-a624-4863-82de-99ac29290840",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7532467532467533\n",
      "Confusion matrix:\n",
      "[[84 15]\n",
      " [23 32]]\n"
     ]
    }
   ],
   "source": [
    "# splitting the dataset into training and testing sets\n",
    "X = df_diabetes.drop(\"Outcome\", axis=1)\n",
    "y = df_diabetes[\"Outcome\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# normalizing the dataset\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# creating the Logistic Regression model\n",
    "lr_model = LogisticRegression()\n",
    "\n",
    "# fit to the train data\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# making predictions on the test data\n",
    "y_pred = lr_model.predict(X_test)\n",
    "\n",
    "# evaluating the model performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Confusion matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d38a927-c22f-4075-8ab9-7afe52a4762f",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a43d66a-a8a6-429c-a93d-3fbc51885dc4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7532467532467533\n",
      "Confusion matrix:\n",
      "[[77 22]\n",
      " [16 39]]\n"
     ]
    }
   ],
   "source": [
    "# splitting the dataset into training and testing sets\n",
    "X = df_diabetes.drop(\"Outcome\", axis=1)\n",
    "y = df_diabetes[\"Outcome\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# creating the Decision Tree model\n",
    "dt_model = DecisionTreeClassifier()\n",
    "\n",
    "# fitting the model on the training data and making predictions on the test data\n",
    "dt_model.fit(X_train, y_train)\n",
    "y_pred = dt_model.predict(X_test)\n",
    "\n",
    "# evaluating the model performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(f\"Confusion matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb187221-af45-49c5-a3fe-abb917571034",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f354e56e-a51a-4875-8861-2223d2b1d309",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7662337662337663\n",
      "Confusion matrix:\n",
      "[[80 19]\n",
      " [17 38]]\n"
     ]
    }
   ],
   "source": [
    "# splitting the dataset into training and testing sets\n",
    "X = df_diabetes.drop(\"Outcome\", axis=1)\n",
    "y = df_diabetes[\"Outcome\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# creating the Random Forest model\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "# fitting the model on the training data and making predictions on the test data\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# evaluating the model performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(f\"Confusion matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656dfd3e-5b67-4d03-96f2-0d1bb185d0f9",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "632caf0d-b67f-47ae-b1df-8b62ee6a182a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7662337662337663\n",
      "Confusion matrix:\n",
      "[[87 12]\n",
      " [24 31]]\n"
     ]
    }
   ],
   "source": [
    "# splitting the dataset into training and testing sets\n",
    "X = df_diabetes.drop(\"Outcome\", axis=1)\n",
    "y = df_diabetes[\"Outcome\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# creating the SVM model\n",
    "svm_model = SVC()\n",
    "\n",
    "# fitting the model on the training data and making predictions on the test data\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "# evaluating the model performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(f\"Confusion matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75158482-55e3-4d24-8831-d8da27072561",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec09d8d2-dc28-4a1e-b01b-0d65d0ba14ec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7467532467532467\n",
      "Confusion matrix:\n",
      "[[78 21]\n",
      " [18 37]]\n"
     ]
    }
   ],
   "source": [
    "# splitting the dataset into training and testing sets\n",
    "X = df_diabetes.drop(\"Outcome\", axis=1)\n",
    "y = df_diabetes[\"Outcome\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# creating the Gradient Boosting model\n",
    "gb_model = GradientBoostingClassifier()\n",
    "\n",
    "# fitting the model on the training data and making predictions on the test data\n",
    "gb_model.fit(X_train, y_train)\n",
    "y_pred = gb_model.predict(X_test)\n",
    "\n",
    "# evaluating the model performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(f\"Confusion matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643bec74-251a-4acc-8fe9-d377886e7d0e",
   "metadata": {},
   "source": [
    "## Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e615b343-eee4-4945-b0cf-f995f8b32947",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6883116883116883\n",
      "Confusion matrix:\n",
      "[[89 10]\n",
      " [38 17]]\n"
     ]
    }
   ],
   "source": [
    "# splitting the dataset into training and testing sets\n",
    "X = df_diabetes.drop(\"Outcome\", axis=1)\n",
    "y = df_diabetes[\"Outcome\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# creating the neural network model\n",
    "nn_model = MLPClassifier(hidden_layer_sizes=(16,8,4), activation='relu', solver='adam', max_iter=200)\n",
    "\n",
    "# fitting the model on the training data and making predictions on the test data\n",
    "nn_model.fit(X_train, y_train)\n",
    "y_pred = nn_model.predict(X_test)\n",
    "\n",
    "# evaluating the model performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(f\"Confusion matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51f042d-9e54-4489-8063-e02819a539af",
   "metadata": {},
   "source": [
    "## Dump the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "183e760b-1c74-407f-b9c6-17f227e3ed9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create folder with name_datestamp\n",
    "name = \"anirudh\"\n",
    "folder_name = datetime.datetime.now().date().strftime(\"%m%d%Y\")\n",
    "folder_path = os.path.join(models_path, name + \"_\" + folder_name)\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)\n",
    "                      \n",
    "\n",
    "with open(os.path.join(folder_path, 'lr_model.pkl'), 'wb') as file:\n",
    "    pickle.dump(lr_model, file)\n",
    "\n",
    "# Dump decision tree model to file\n",
    "with open(os.path.join(folder_path, 'dt_model.pkl'), 'wb') as file:\n",
    "    pickle.dump(dt_model, file)\n",
    "\n",
    "# Dump random forest model to file\n",
    "with open(os.path.join(folder_path, 'rf_model.pkl'), 'wb') as file:\n",
    "    pickle.dump(rf_model, file)\n",
    "\n",
    "# Dump SVM model to file\n",
    "with open(os.path.join(folder_path, 'svm_model.pkl'), 'wb') as file:\n",
    "    pickle.dump(svm_model, file)\n",
    "\n",
    "# Dump gradient boosting model to file\n",
    "with open(os.path.join(folder_path, 'gb_model.pkl'), 'wb') as file:\n",
    "    pickle.dump(gb_model, file)\n",
    "\n",
    "# Dump neural network model to file\n",
    "with open(os.path.join(folder_path, 'nn_model.pkl'), 'wb') as file:\n",
    "    pickle.dump(nn_model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc12219-a7e6-4815-aeec-7e6af537e58f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3ecdda-b54e-44d6-9ddf-52b5540c5df4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce44a229-4561-4e04-9176-65a99c80f3c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
